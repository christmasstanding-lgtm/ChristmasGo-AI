import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_id = "microsoft/phi-2"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id)

generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

def generate_challenge(prompt):
    full_prompt = f"Cr√©e un d√©fi festif pour le jeu ChristmasGo sur le th√®me : {prompt}"
    result = generator(full_prompt, max_new_tokens=100, temperature=0.8, top_p=0.95)
    return result[0]['generated_text'].replace(full_prompt, "").strip()

interface = gr.Interface(
    fn=generate_challenge,
    inputs=gr.Textbox(placeholder="Ex: 'Rennes', 'Sapin', 'Chocolat chaud'", label="Th√®me du d√©fi"),
    outputs=gr.Textbox(label="D√©fi g√©n√©r√©"),
    title="üéÑ G√©n√©rateur de d√©fis ChristmasGo",
    description="Entrez un th√®me festif et recevez un d√©fi original pour le jeu ChristmasGo.",
    theme="soft",
    examples=[["P√¥le Nord"], ["Bonhomme de neige"], ["Tra√Æneau magique"]]
)

if __name__ == "__main__":
    interface.launch()
